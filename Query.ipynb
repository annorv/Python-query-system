{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e446713",
   "metadata": {},
   "source": [
    "# Simple Bible Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a692405b",
   "metadata": {},
   "source": [
    "### Installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af22517",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyPDF2 nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "965f61a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb77fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65ca130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(file_path):\n",
    "    # Open the PDF file in binary mode\n",
    "    with open(file_path, 'rb') as file:\n",
    "        # Create a PdfReader object from the PDF file\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        # Get the total number of pages in the PDF\n",
    "        num_pages = len(pdf_reader.pages)\n",
    "        \n",
    "        # Initialise a list to store content from each page\n",
    "        content = []\n",
    "        \n",
    "        # Iterate through each page in the PDF\n",
    "        for page_num in range(num_pages):\n",
    "            # Extract text content from the current page\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            content.append(page.extract_text())\n",
    "    \n",
    "    # Combine the text content from all pages into a single string\n",
    "    return '\\n'.join(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "072661a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vannor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the 'punkt' resource from NLTK (Natural Language Toolkit)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Import the sentence tokenizer from NLTK\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def tokenize_text(text):\n",
    "    # Tokenize the input text into sentences using NLTK's sentence tokenizer\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d78b1f6",
   "metadata": {},
   "source": [
    "### Using BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5eff03",
   "metadata": {},
   "source": [
    "BERT, or Bidirectional Encoder Representations from Transformers, is a powerful natural language processing model that excels in understanding contextual relationships in text by considering both left and right contexts of words, allowing it to capture intricate semantic meanings and perform various language understanding tasks with high accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bd0180e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask a question: what is the first book of the bible\n",
      "Answer: Genesis\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the question answering pipeline\n",
    "qa_pipeline = pipeline('question-answering', model='bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "def process_query_bert(text, query):\n",
    "    # Use BERT for question answering\n",
    "    result = qa_pipeline(context=text, question=query)\n",
    "    \n",
    "    # Check if the answer confidence is above a certain threshold\n",
    "    if result['score'] > 0.5:\n",
    "        return f\"Answer: {result['answer']}\"\n",
    "    \n",
    "    return \"No relevant information found for the query.\"\n",
    "\n",
    "# Usage example:\n",
    "file_path = 'bible_facts2.pdf'\n",
    "document_content = read_pdf(file_path)\n",
    "\n",
    "# Prompt the user to input a question\n",
    "user_query = input(\"Ask a question: \")\n",
    "\n",
    "# Process the user's query using BERT and print the result\n",
    "result = process_query_bert(document_content, user_query)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08e8796",
   "metadata": {},
   "source": [
    "### Adjusting the code to create a loop allowing users to keep asking questions without rerunning the entire script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a7ffa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask a question (type 'exit' to end): what is the first book of the bible\n",
      "Answer: Genesis\n",
      "Ask a question (type 'exit' to end): what is the first last of the bible\n",
      "No relevant information found for the query.\n",
      "Ask a question (type 'exit' to end): what is the shortest verseof the bible\n",
      "No relevant information found for the query.\n",
      "Ask a question (type 'exit' to end): what is the shortest verse in the bible\n",
      "No relevant information found for the query.\n",
      "Ask a question (type 'exit' to end): what does bible mean\n",
      "No relevant information found for the query.\n",
      "Ask a question (type 'exit' to end): what is the first book of the bible\n",
      "Answer: Genesis\n",
      "Ask a question (type 'exit' to end): first book of the biblw\n",
      "No relevant information found for the query.\n",
      "Ask a question (type 'exit' to end): first book of the bible\n",
      "No relevant information found for the query.\n",
      "Ask a question (type 'exit' to end): number of books in the old testament\n",
      "Answer: 39\n",
      "Ask a question (type 'exit' to end): how many books are there in the old testament\n",
      "Answer: 39\n",
      "Ask a question (type 'exit' to end): number of books in the newv testament\n",
      "No relevant information found for the query.\n",
      "Ask a question (type 'exit' to end): number of books in the new testament\n",
      "Answer: 27\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the question answering pipeline\n",
    "qa_pipeline = pipeline('question-answering', model='bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "def process_query_bert(text, query):\n",
    "    \"\"\"\n",
    "    Process a user query using BERT-based question answering.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The document or context for BERT to analyze.\n",
    "    - query (str): The user's question to be answered.\n",
    "\n",
    "    Returns:\n",
    "    - str: The answer to the user's question or a message indicating no relevant information.\n",
    "    \"\"\"\n",
    "    # Use BERT for question answering\n",
    "    result = qa_pipeline(context=text, question=query)\n",
    "    \n",
    "    # Check if the answer confidence is above a certain threshold\n",
    "    if result['score'] > 0.5:\n",
    "        return f\"Answer: {result['answer']}\"\n",
    "    \n",
    "    return \"No relevant information found for the query.\"\n",
    "\n",
    "# Usage example:\n",
    "file_path = 'bible_facts2.pdf'\n",
    "document_content = read_pdf(file_path)\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"Ask a question (type 'exit' to end): \")\n",
    "    \n",
    "    if user_query.lower() == 'exit':\n",
    "        print(\"Exiting the question-answering loop.\")\n",
    "        break\n",
    "    \n",
    "    result = process_query_bert(document_content, user_query)\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
